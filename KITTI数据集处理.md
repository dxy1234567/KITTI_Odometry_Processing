# KITTI数据集处理

### 1. 点云数据 KITTI_Odometry

我们希望通过KITTI的相关数据，利用激光雷达点云图、位姿信息、外参信息，将激光雷达的点云先进行多帧拼接，然后向前投影到相机的投影平面中，以得到较为稠密的深度图。下面将从KITTI的数据等角度介绍KITTI的相关数据以及点云投影的具体方法。

KITTI数据集中共有21个序列`sequences`。下列的讨论以序列`00`为例。

每个序列中均含有4541个时间戳的信息，其中<u>每个时间戳</u>的信息包含**相机灰度图**、**激光雷达点云图**、**位姿信息**及其他信息。另外，<u>每个序列</u>信息中还会包含实验平台的**外参信息**。这里的相机图像一般会包含两组，以灰度图像为例，组织形式为`image_0`和`image_1`的信息分别表示和**相机左灰度摄像头**和**相机右灰度摄像头**采集到的数据。而在下文中，均采取左摄像头采集到的图像作为图像信息。

原点云数据为`.bin`格式，需要通过`numpy`库来转换为`.pcd`。

我们将时刻$t$激光雷达`Veledyne`获取到的点定义为$P_L^t$。

#### 1.1. 点云数据坐标轴

x轴向前；y轴向左；z轴向上。

#### 1.2. 位姿信息

在每个序列信息中，每个时间戳都会有对应的位姿信息，其中位姿信息可以转换为变换矩阵。因此，这里我们将时刻$t$对应的位姿信息为$T^t_{WL}$，且有
$$
P^t_W = T_{WL}^t \cdot P_L^t。
$$


#### 1.3. 点云拼接

先将点云转换为`open3d.PointCloud`格式，通过位姿信息直接将多帧点云转换到同一坐标系（世界坐标系）下得到11帧拼接出的点云`combined_pcd`。

>【已解决】
>
>- 问题：拼接出来的点云信息y轴向下。
>
>- 回答：世界坐标系是以初始时刻的相机坐标系为基准的，所以通过位姿信息拼接出的点云是以相机坐标系为基准的，即z轴向前；y轴向下。

这里我们将时刻$t$及前5帧和后5帧，共11帧点云信息进行拼接，且将时刻$t$在世界坐标系下拼接出的点云定义为$CP_W^t$，则有
$$
CP_W^t = \sum_{i=t-5}^{t+5}P_W^i = T_{WL}^i \cdot P_L^i。
$$

#### 1.4. 坐标系转换

实际上，在点云拼接的过程中就已经涉及到了坐标系的转换。在这里的坐标系转换中，强调的是拼接点云从世界坐标系转换到特定的时刻$t$中的雷达坐标系中，即
$$
\begin{aligned}
        &   & CP_L^t = T_{LW}^t \cdot CP_W^t \\
s.t.    &   & T_{LW}^t = (T^t_{WL})^{-1}。
\end{aligned}
$$

#### 1.5. 外参信息

经过坐标系转换后，拼接点云信息已经转换到了当前时刻$t$的激光雷达坐标系下，我们还要将点云信息转换到当前时刻$t$的相机坐标系下并进行投影。

KITTI给出的外参信息中，我们此处能够利用的有`P0`行和`Tr`行，其中`P0`行给出了相机的内参信息$K$，而`Tr`给出了从激光雷达到相机左灰度摄像头的变换信息$T_{CL}$。则有
$$
CP_C^t = T_{CL} \cdot CP_L^t。
$$

#### 1.6. 点云投影

多帧点云拼接后得到拼接点云，拼接点云再经过多次坐标系变换后最后转移到了时刻$t$的相机坐标系下。最后，我们取相机前方的所有点（`z>0`），并投影到相机投影平面上，即得到一个较为稠密的深度图。



---

### 问题更新

#### 1）20241017位姿信息

发现位姿信息是针对左灰度摄像头（`Cam 0`）的，即上文提到的有关位姿信息（1.2节）的计算可能存在错误，导致拼接出的点云可能存在错误。

也就是说，给出的数据是针对`Cam 0`的，我们给位姿信息的标号应为$T_{WC}^t$，为了使整体的工程与体系大部不变，下文将利用外参信息来采取“修正”位姿信息的方法，以获得我们真正想要的位姿信息$T^t_{WL}$。

已知表达式
$$
P_W^t = T_{WC}^t \cdot P_C^t，\tag{1}
$$
而我们希望得到的转换信息（位姿信息）$T'^t$及对应的表达式为
$$
P_W^t = T'^t \cdot P_L^t，\tag{2}
$$
即我们希望求$T'^t$。另外，我们有外参信息$T_{CL}$，且表达式如下。
$$
P_C^t = T_{CL} \cdot P_L^t。\tag{3}
$$
结合$(1)，(3)$可得
$$
P_W^t = T_{WC}^t \cdot T_{CL} \cdot P_L^t。\tag{4}
$$
即
$$
T'^t = T_{WC}^t \cdot T_{CL}。\tag{5}
$$
综上所述，我们希望得到的位姿信息$T_{WL}^t$应为
$$
T_{WL}^t = T'^t = T_{WC}^t \cdot T_{CL}。
$$


#### 2）20241019点云坐标系变换

在工作前期过程中，一直出现有点云投影无法对其图像的问题，该过程主要涉及点云的坐标系变换问题。而本工程的主要任务是将激光雷达的点云向前投影到相机坐标系下的投影平面上，期间涉及到多个坐标系的转换。而在坐标系变换过程中，有两个函数会与其有关，一个是`pcd.transform(T)`，另一个是`cv2.projectPoints`。

- `pcd.transform(T)`

  `pcd`表示点云在某一坐标系下的多点信息，而`transform`函数的作用是将`pcd`中的所有点经过变换矩阵$T$，变换到另一个新的坐标系中。

- `cv2.projectPoints()`

  ```python
  imagePoints, jacobian = cv2.projectPoints(objectPoints, rvec, tvec, cameraMatrix, distCoeffs[, imagePoints[, jacobian[, aspectRatio]]])
  ```

  其中输入参数`rvec`和`tvec`也对应着一次坐标系的变换。

  在之前的工程过程中，总是存在着点云投影无法对齐图像的问题。本人一度怀疑是点云数据出错。然而，事实表明似乎是`cv2.projectPoints`函数的坐标系变换存在着问题。

在最后的尝试中，我将坐标系变换的需求全部给予`transform`函数上，而`cv2.projectPoints`函数的旋转向量和平移向量全部置零。投影结果是良好的，这表明`cv2.projectPoints`的使用存在着问题。故在代码的使用中`cv2.projectPoints`并没有坐标系转换的功能。

